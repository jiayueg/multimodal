{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "N7fApNF7xjy3"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install scprep\n",
    "!pip install anndata\n",
    "!pip install scanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-L0n8_rB7gPQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import scprep\n",
    "import scanpy as sc\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tempfile\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import load_raw\n",
    "import normalize_tools as nm\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIaWncv9FRlG"
   },
   "source": [
    "# **try out with scicar cell lines dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kdBrFDRFj-x"
   },
   "source": [
    "**1. URLs for raw data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_data, atac_data, rna_cells, atac_cells, rna_genes, atac_genes = load_raw.load_raw_cell_lines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcF3DwMRMGPl"
   },
   "source": [
    "**2. select the joint sub-datasets** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vmgqCzKUTtpo"
   },
   "outputs": [],
   "source": [
    "scicar_data, joint_index, keep_cells_idx = load_raw.merge_data(rna_data, atac_data, rna_cells, atac_cells, rna_genes, atac_genes)\n",
    "#rna_df, atac_df = ann2df(scicar_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip(adata, prop_clip=0.5):\n",
    "    assert isinstance(prop_clip, float) and 0.0 < prop_clip < 50.0\n",
    "    clip_low, clip_high = np.percentile(adata.X.flatten(), [prop_clip, 100 - prop_clip])\n",
    "    adata.X = np.clip(adata.X, clip_low, clip_high)\n",
    "    \n",
    "def preprocess(\n",
    "    adata,\n",
    "    binarize=True,\n",
    "    filter_gene_min_counts=5, \n",
    "    filter_gene_min_cells=5,\n",
    "    filter_gene_max_cells=0.1,\n",
    "    size_factor=True, \n",
    "    log_trans=True, \n",
    "    normalize=True, \n",
    "    proportion=None,\n",
    "    prop_clip=0.5,\n",
    "):\n",
    "    #preprocess for RNA modality \n",
    "    #(log tranform normalize and scale to zero mena unit variance)\n",
    "    nm.normalize_count_table(adata, proportion=proportion)\n",
    "    clip(adata, prop_clip=prop_clip)\n",
    "    \n",
    "    #preprocess for ATAC modality (binarize and filter)\n",
    "    if binarize:\n",
    "        nm.binarize(adata, obsm=\"mode2\", obs=\"mode2_obs\", var=\"mode2_var\")\n",
    "    nm.filter_adata(\n",
    "        adata, \n",
    "        filter_gene_min_counts=5, \n",
    "        filter_gene_min_cells=5,\n",
    "        filter_gene_max_cells=0.1,\n",
    "        obsm=\"mode2\",\n",
    "        obs=\"mode2_obs\",\n",
    "        var=\"mode2_var\",\n",
    "    )\n",
    "    \n",
    "    if not isinstance(adata.X, scipy.sparse.csr_matrix):\n",
    "        adata.X = scipy.sparse.csr_matrix(adata.X)\n",
    "        \n",
    "    #figure out the obs and var info for adata\n",
    "    adata.uns[\"mode2_obs\"] = np.array(adata.uns[\"mode2_obs\"][0])\n",
    "    adata.uns[\"mode2_var\"] = np.array(adata.uns[\"mode2_var\"][0])\n",
    "    adata.uns = {\"mode2_obs\": adata.uns[\"mode2_obs\"], \"mode2_var\": adata.uns[\"mode2_var\"]}\n",
    "    \n",
    "    dim_mode1 = adata.X.shape[1]\n",
    "    dim_mode2 = adata.obsm[\"mode2\"].shape[1]\n",
    "    return adata, dim_mode1, dim_mode2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATAC_KWARGS = {\n",
    "    \"binarize\": False,\n",
    "    \"filter_gene_min_counts\": 5, \n",
    "    \"filter_gene_min_cells\": 5,\n",
    "    \"filter_gene_max_cells\": 0.1,\n",
    "}\n",
    "\n",
    "RNA_KWARGS = {\n",
    "    \"size_factor\": True, \n",
    "    \"log_trans\": True, \n",
    "    \"normalize\": True, \n",
    "    \"proportion\": None,\n",
    "    \"prop_clip\": 0.5,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw, test_data_raw, indices_train, mask_test= load_raw.train_test_split(scicar_data)\n",
    "scicar_data_filtered, dim_rna, dim_atac = preprocess(scicar_data, **ATAC_KWARGS, **RNA_KWARGS)\n",
    "train_data_filtered, test_data_filtered = load_raw.split_with_mask(scicar_data_filtered, indices_train, mask_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hD2gQCx6iIlc"
   },
   "source": [
    "# **define pytorch datasets for RNA and ATAC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qQdzukDtFhu"
   },
   "outputs": [],
   "source": [
    "class Merge_Dataset(Dataset):\n",
    "    def __init__(self, adata_raw, adata_filtered):\n",
    "        self.rna_data_filtered, self.atac_data_filtered = self._load_merge_data(adata_filtered)\n",
    "        self.rna_data_raw = self._load_raw_ref_data(adata_raw)\n",
    "        \n",
    "    def __len__(self):\n",
    "        #assert(len(self.rna_data) == len(self.atac_data))\n",
    "        return len(self.atac_data_filtered)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        rna_filtered = self.rna_data_filtered.values[idx]\n",
    "        atac_filtered = self.atac_data_filtered.values[idx]\n",
    "        rna_raw = self.rna_data_raw.values[idx]\n",
    "        #return a tensor that for a single observation\n",
    "        return [\n",
    "            torch.from_numpy(rna_filtered).float(), \n",
    "            torch.from_numpy(atac_filtered).float(),\n",
    "            torch.from_numpy(rna_raw).float(),\n",
    "        ]\n",
    "  \n",
    "    def _load_merge_data(self, adata):\n",
    "        rna_df = pd.DataFrame(\n",
    "            data = adata.X.toarray(), \n",
    "            index = np.array(adata.obs.index), \n",
    "            columns = np.array(adata.var.index),\n",
    "        )\n",
    "        atac_df = pd.DataFrame(\n",
    "            data = adata.obsm[\"mode2\"].toarray(),\n",
    "            index = np.array(adata.uns[\"mode2_obs\"]),\n",
    "            columns = np.array(adata.uns[\"mode2_var\"]),\n",
    "        )\n",
    "        return rna_df, atac_df\n",
    "    \n",
    "    def _load_raw_ref_data(self, adata_raw):\n",
    "        rna_df = pd.DataFrame(\n",
    "            data = adata_raw.X.toarray(), \n",
    "            index = np.array(adata_raw.obs.index), \n",
    "            columns = np.array(adata_raw.var.index),\n",
    "        )\n",
    "        return rna_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4szWON2-cpvS"
   },
   "source": [
    "# **Compute DCCA loss (-corr(H1, H2))**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-6pKoruco26"
   },
   "outputs": [],
   "source": [
    "class cca_loss():\n",
    "    def __init__(self, out_dim, device, use_all_singvals=False):\n",
    "        self.out_dim = out_dim #parameter o in original paper\n",
    "        self.use_all_singvals = use_all_singvals\n",
    "        self.device = device\n",
    "  \n",
    "    def loss(self, H1, H2):\n",
    "        r1 = 1e-3\n",
    "        r2 = 1e-3\n",
    "        eps = 1e-9\n",
    "\n",
    "        #transpose H1, H2: m x o -> o x m\n",
    "        H1 = H1.t()\n",
    "        H2 = H2.t()\n",
    "        #assert torch.isnan(H1).sum().item() == 0\n",
    "        #assert torch.isnan(H2).sum().item() == 0\n",
    "\n",
    "        m = H1.size(1)\n",
    "        o1, o2 = H1.size(0), H2.size(0)\n",
    "\n",
    "        #produce the centered data matrices: H1 - 1/m*H1Â·I (same for H2bar)\n",
    "        H1bar = H1 - H1.mean(dim=1).unsqueeze(dim=1)\n",
    "        H2bar = H2 - H2.mean(dim=1).unsqueeze(dim=1)\n",
    "        assert torch.isnan(H1bar).sum().item() == 0\n",
    "        assert torch.isnan(H2bar).sum().item() == 0\n",
    "\n",
    "        SigmaHat12 = (1.0/(m-1))*torch.matmul(H1bar, H2bar.t())\n",
    "        SigmaHat11 = (1.0/(m-1))*torch.matmul(H1bar, H1bar.t()) + r1*torch.eye(o1, device=self.device)\n",
    "        SigmaHat22 = (1.0/(m-1))*torch.matmul(H2bar, H2bar.t()) + r2*torch.eye(o2, device=self.device)\n",
    "        #assert torch.isnan(SigmaHat11).sum().item() == 0\n",
    "        #assert torch.isnan(SigmaHat12).sum().item() == 0\n",
    "        #assert torch.isnan(SigmaHat22).sum().item() == 0\n",
    "\n",
    "        #calculate the root inverse (e.g. SigmaHat11^(-1/2)) using sigular value decomposition\n",
    "        D1, V1 = torch.symeig(SigmaHat11, eigenvectors=True)\n",
    "        D2, V2 = torch.symeig(SigmaHat22, eigenvectors=True)\n",
    "\n",
    "        # ??? probably problemetic in gene count setting\n",
    "        posIdx1 = torch.gt(D1, eps).nonzero()[:, 0]\n",
    "        D1 = D1[posIdx1]\n",
    "        V1 = V1[:, posIdx1]\n",
    "\n",
    "        posIdx2 = torch.gt(D2, eps).nonzero()[:, 0]\n",
    "        D2 = D2[posIdx2]\n",
    "        V2 = V2[:,posIdx2]\n",
    "\n",
    "        #???take care of torch.sqrt\n",
    "        SigmaHatRootInv11 = torch.matmul(torch.matmul(V1, torch.diag((D1)**(-0.5))), V1.t())\n",
    "        SigmaHatRootInv22 = torch.matmul(torch.matmul(V2, torch.diag((D2)**(-0.5))), V2.t())\n",
    "\n",
    "        #calculate T\n",
    "        Tval = torch.matmul(torch.matmul(SigmaHatRootInv11, SigmaHat12), SigmaHatRootInv22)\n",
    "\n",
    "        #calculate corr(H1, H2): matrix trace norm of T or sum of top k singular vals of T\n",
    "        trace_TT = torch.matmul(Tval.t(), Tval)\n",
    "        if self.use_all_singvals:\n",
    "            corr = torch.trace(torch.sqrt(trace_TT))\n",
    "            #assert torch.isnan(corr).item() == 0\n",
    "        else:\n",
    "            trace_TT = torch.add(trace_TT, (torch.eye(trace_TT.shape[0])*r1).to(self.device))\n",
    "            U, V = torch.symeig(trace_TT, eigenvectors=True)\n",
    "            U = torch.where(U>eps, U, (torch.ones(U.shape).float()*eps).to(self.device))\n",
    "            U = U.topk(self.out_dim)[0]\n",
    "            corr = torch.sum(torch.sqrt(U))\n",
    "            #print(\"loss: \" + str(-corr))\n",
    "        return -corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructureHingeLoss(nn.Module):\n",
    "    def __init__(self, margin, max_val, lamb_match, lamb_nn, device):\n",
    "        super(StructureHingeLoss, self).__init__()\n",
    "        self.margin = margin\n",
    "        self.max_val = max_val\n",
    "        self.lamb_match = lamb_match\n",
    "        self.lamb_nn = lamb_nn\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, rna_outputs, atac_outputs, nn_indices):\n",
    "        #rna_outputs: n_batch x n_latent\n",
    "        #atac_outputs: n_batch x n_latent\n",
    "        assert rna_outputs.shape[0] == atac_outputs.shape[0]\n",
    "        assert rna_outputs.shape[1] == atac_outputs.shape[1]\n",
    "        n_batch = rna_outputs.shape[0]\n",
    "        \n",
    "        #calculated pairwise L2 distance\n",
    "        #dist_rna_atac[i][j]: the L2 distance between RNA embedding i\n",
    "        #and ATAC embedding j (n_batch x n_batch)\n",
    "        #constraint for ensuring every rna embedding is close to matched atac embedding\n",
    "        dist_rna_atac = torch.cdist(rna_outputs, atac_outputs, p=2)\n",
    "        match_labels = torch.eye(n_batch).to(self.device)\n",
    "        match_mask = match_labels > 0\n",
    "        pos_match_dist = torch.masked_select(dist_rna_atac, match_mask).view(n_batch, 1)\n",
    "        neg_match_dist = torch.masked_select(dist_rna_atac, ~match_mask).view(n_batch, -1)\n",
    "        \n",
    "        loss_match_rna = torch.clamp(self.margin + pos_match_dist - neg_match_dist, 0, self.max_val)\n",
    "        loss_match_rna = loss_match_rna.mean()\n",
    "        #print(f\"loss_match_rna: {loss_match_rna}\")\n",
    "        \n",
    "        #constraint for ensuring every atac embedding is close to matched rna embedding\n",
    "        dist_atac_rna = dist_rna_atac.t()\n",
    "        pos_match_dist = torch.masked_select(dist_atac_rna, match_mask).view(n_batch, 1)\n",
    "        neg_match_dist = torch.masked_select(dist_atac_rna, ~match_mask).view(n_batch, -1)\n",
    "        \n",
    "        loss_match_atac = torch.clamp(self.margin + pos_match_dist - neg_match_dist, 0, self.max_val)\n",
    "        loss_match_atac = loss_match_rna.mean()\n",
    "        #print(f\"loss_match_atac: {loss_match_atac}\")\n",
    "        \n",
    "        #constraint for ensuring that every RNA embedding is close to \n",
    "        #the neighboring RNA embeddings.\n",
    "        nn_masked = torch.zeros(n_batch, n_batch).to(self.device)\n",
    "        nn_masked.scatter_(1, nn_indices, 1.)\n",
    "        nn_masked = nn_masked > 0\n",
    "        \n",
    "        dist_rna_rna = torch.cdist(rna_outputs, rna_outputs, p=2)\n",
    "        \n",
    "        #pos_rna_nn_dist: n_batch x n_neighbor\n",
    "        pos_rna_nn_dist = torch.masked_select(dist_rna_rna, nn_masked).view(n_batch, -1)\n",
    "        neg_rna_nn_dist = torch.masked_select(dist_rna_rna, ~nn_masked).view(n_batch, -1)\n",
    "        rna_nn_loss = torch.clamp(self.margin + pos_rna_nn_dist[...,None] - neg_rna_nn_dist[..., None, :], 0, self.max_val)\n",
    "        rna_nn_loss = rna_nn_loss.mean()\n",
    "        #print(f\"rna_nn_loss: {rna_nn_loss}\")\n",
    "        \n",
    "        #constraint for ensuring that every ATAC embedding is close to \n",
    "        #the neighboring ATAC embeddings.\n",
    "        dist_atac_atac = torch.cdist(atac_outputs, atac_outputs, p=2)\n",
    "        #pos_rna_nn_dist: n_batch x n_neighbor\n",
    "        pos_atac_nn_dist = torch.masked_select(dist_atac_atac, nn_masked).view(n_batch, -1)\n",
    "        neg_atac_nn_dist = torch.masked_select(dist_atac_atac, ~nn_masked).view(n_batch, -1)\n",
    "        atac_nn_loss = torch.clamp(self.margin + pos_atac_nn_dist[...,None] - neg_atac_nn_dist[..., None, :], 0, self.max_val)\n",
    "        atac_nn_loss = atac_nn_loss.mean()\n",
    "        #print(f\"atac_nn_loss: {atac_nn_loss}\")\n",
    "        \n",
    "        loss = (self.lamb_match * loss_match_rna \n",
    "                + self.lamb_match * loss_match_atac\n",
    "                + self.lamb_nn * rna_nn_loss \n",
    "                + self.lamb_nn * atac_nn_loss)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Reconstruction Loss Using Decoder for each AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_loss(x, x_recon, y, y_recon):\n",
    "    MSE = nn.MSELoss()\n",
    "    x_loss = MSE(x, x_recon)\n",
    "    y_loss = MSE(y, y_recon)\n",
    "    total_loss = x_loss + y_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUl-7w_gcmto"
   },
   "source": [
    "# **define basic models(now just encoder net) for learning latent space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_input, n_latent, layer_sizes):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_input = n_input\n",
    "        self.n_latent = n_latent\n",
    "        self.layer_sizes = [n_input] + layer_sizes + [n_latent]\n",
    "        self.encoder_layers = []\n",
    "        \n",
    "        for idx in range(len(self.layer_sizes) - 1):\n",
    "            fc1 = nn.Linear(self.layer_sizes[idx], self.layer_sizes[idx + 1])\n",
    "            nn.init.xavier_uniform_(fc1.weight)\n",
    "            self.encoder_layers.append(fc1)\n",
    "            bn1 = nn.BatchNorm1d(self.layer_sizes[idx + 1])\n",
    "            self.encoder_layers.append(bn1)\n",
    "            act1 = nn.PReLU()\n",
    "            self.encoder_layers.append(act1)\n",
    "            \n",
    "        self.encoder = nn.Sequential(*self.encoder_layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return(self.encoder(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iq4Q758AZn3W"
   },
   "source": [
    "# Assembly Neural Net And Loss Into DCCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yiiicKn7ZaVo"
   },
   "outputs": [],
   "source": [
    "class DCCA(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        n_input1, \n",
    "        n_input2, \n",
    "        layer_sizes1, \n",
    "        layer_sizes2, \n",
    "        n_out, \n",
    "        use_all_singvals=False, \n",
    "        device=torch.device(\"cpu\"), \n",
    "        use_decode = False, \n",
    "        seed=182822,\n",
    "    ):\n",
    "        super(DCCA, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.Net1 = Encoder(n_input1, n_latent=n_out, layer_sizes=layer_sizes1)\n",
    "        self.Net2 = Encoder(n_input2, n_latent=n_out, layer_sizes=layer_sizes2)\n",
    "        self.cca_loss = cca_loss(out_dim=n_out, use_all_singvals=use_all_singvals, device=device).loss\n",
    "        self.recon_loss = recon_loss\n",
    "        \n",
    "        self.device = device\n",
    "        self.use_decode = use_decode\n",
    "        \n",
    "    def forward(self, x1, x2):\n",
    "        z1 = self.Net1(x1)\n",
    "        embed1 = F.normalize(z1, dim=1, p=2)\n",
    "        z2 = self.Net2(x2)\n",
    "        embed2 = F.normalize(z2, dim=1, p=2)\n",
    "        return embed1, embed2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsbRfruLdE2j"
   },
   "source": [
    "# **Train Basic Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0AH8OM02c71Y"
   },
   "outputs": [],
   "source": [
    "#set up all hyper-parameters\n",
    "hyper = {\n",
    "    \"nEpochs\":100,\n",
    "    \"dim_rna\":dim_rna,\n",
    "    \"dim_atac\":dim_atac,\n",
    "    \"n_latent\":32,\n",
    "    \"layer_sizes\":[256, 64],\n",
    "    \"add_hinge\":True,\n",
    "    \"lamb_match\":1,\n",
    "    \"lamb_nn\":1.5,\n",
    "    \"lamb_hinge\":10,\n",
    "    \"train_batch\":256,\n",
    "    \"test_batch\": 512,\n",
    "    \"lr\": 1e-3,\n",
    "    \"clip_grad\": 1,\n",
    "    \"checkpoint_path\": './checkpoint/best_model_dcca_hinge.pt',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    n_svd = 100\n",
    "    proportion_neighbors = 0.1\n",
    "    \n",
    "    rna_inputs_filtered, atac_inputs_filtered, rna_inputs_raw = zip(*batch)\n",
    "    rna_inputs_filtered = torch.stack(rna_inputs_filtered)\n",
    "    atac_inputs_filtered = torch.stack(atac_inputs_filtered)\n",
    "    rna_inputs_raw = torch.stack(rna_inputs_raw)\n",
    "    \n",
    "    n_svd = min([n_svd, min(rna_inputs_raw.shape) - 1])\n",
    "    n_neighbors = int(np.ceil(proportion_neighbors * rna_inputs_raw.shape[0]))\n",
    "    X_pca = sklearn.decomposition.TruncatedSVD(n_svd).fit_transform(rna_inputs_raw)\n",
    "    _, indices_true = (\n",
    "        sklearn.neighbors.NearestNeighbors(n_neighbors=n_neighbors).fit(X_pca).kneighbors(X_pca)\n",
    "    )\n",
    "    \n",
    "    return rna_inputs_filtered, atac_inputs_filtered, rna_inputs_raw, torch.from_numpy(indices_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ToOEhyd6m-ZB"
   },
   "outputs": [],
   "source": [
    "#load dataset and split train and test data\n",
    "#load dataset and split train and test data\n",
    "def get_data_loaders(train_data_filtered, test_data_filtered, train_data_raw, test_data_raw):\n",
    "    train_set = Merge_Dataset(train_data_raw, train_data_filtered)\n",
    "    test_set = Merge_Dataset(test_data_raw, test_data_filtered)\n",
    "    #load data loader\n",
    "    train_loader = DataLoader(\n",
    "        train_set, \n",
    "        batch_size=hyper[\"train_batch\"], \n",
    "        collate_fn=collate_fn,\n",
    "        drop_last=False, \n",
    "        shuffle=True,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_set, \n",
    "        batch_size=hyper[\"test_batch\"], \n",
    "        collate_fn=collate_fn,\n",
    "        drop_last=False, \n",
    "        shuffle=False,\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HZZgU6o2Vv5"
   },
   "outputs": [],
   "source": [
    "#use GPU if available\n",
    "my_device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_criteria(rna_inputs, rna_outputs, atac_outputs, proportion_neighbors=0.1, n_svd=100):\n",
    "    n_svd = min([n_svd, min(rna_inputs.shape)-1])\n",
    "    n_neighbors = int(np.ceil(proportion_neighbors*rna_inputs.shape[0]))\n",
    "    X_pca = sklearn.decomposition.TruncatedSVD(n_svd).fit_transform(rna_inputs)\n",
    "    _, indices_true = (\n",
    "        sklearn.neighbors.NearestNeighbors(n_neighbors = n_neighbors).fit(X_pca).kneighbors(X_pca)\n",
    "    )\n",
    "    _, indices_pred = (\n",
    "        sklearn.neighbors.NearestNeighbors(n_neighbors=n_neighbors).fit(rna_outputs).kneighbors(atac_outputs)\n",
    "    )\n",
    "    neighbors_match = np.zeros(n_neighbors, dtype=int)\n",
    "    for i in range(rna_inputs.shape[0]):\n",
    "        _, pred_matches, true_matches = np.intersect1d(\n",
    "            indices_pred[i], indices_true[i], return_indices=True\n",
    "        )\n",
    "        neighbors_match_idx = np.maximum(pred_matches, true_matches)\n",
    "        neighbors_match += np.sum(np.arange(n_neighbors) >= neighbors_match_idx[:, None], axis = 0,)\n",
    "    neighbors_match_curve = neighbors_match/(np.arange(1, n_neighbors + 1) * rna_inputs.shape[0])\n",
    "    area_under_curve = np.mean(neighbors_match_curve)\n",
    "    return area_under_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E0nHEL8K7EZ0",
    "outputId": "33037275-08dd-443b-b305-783fcc90998b"
   },
   "outputs": [],
   "source": [
    "#set up train functions\n",
    "def main():\n",
    "    #load training data and testing data\n",
    "    train_loader, test_loader = get_data_loaders(\n",
    "        train_data_filtered, \n",
    "        test_data_filtered,\n",
    "        train_data_raw,\n",
    "        test_data_raw,\n",
    "    )\n",
    "    \n",
    "    #load checkpoint\n",
    "    checkpoint = torch.load(hyper[\"checkpoint_path\"])\n",
    "    \n",
    "    #load basic models\n",
    "    dcca_model = DCCA(\n",
    "        n_input1=hyper[\"dim_rna\"], \n",
    "        n_input2=hyper[\"dim_atac\"], \n",
    "        layer_sizes1=hyper[\"layer_sizes\"], \n",
    "        layer_sizes2=hyper[\"layer_sizes\"], \n",
    "        n_out=hyper[\"n_latent\"],\n",
    "        use_all_singvals=False,\n",
    "        device=torch.device(my_device), \n",
    "        use_decode = False,\n",
    "    )\n",
    "    dcca_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    #set up optimizer\n",
    "    dcca_opt = optim.Adam(list(dcca_model.parameters()), lr=hyper[\"lr\"])\n",
    "    dcca_scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        dcca_opt, \n",
    "        patience=10,\n",
    "        factor=0.5,\n",
    "        threshold=0.3, \n",
    "        threshold_mode=\"abs\",\n",
    "        min_lr=1e-5,\n",
    "    )\n",
    "    \n",
    "    #set up device \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    dcca_model.to(device)\n",
    "    \n",
    "    #keep track of best knn accuracy on dev set\n",
    "    best_knn_auc = checkpoint[\"dev_acc\"]\n",
    "    \n",
    "    #training step\n",
    "    for epoch in range(hyper[\"nEpochs\"]):\n",
    "        train_losses = []\n",
    "        for idx, (rna_inputs_filtered, atac_inputs_filtered, rna_inputs_raw, nn_indices) in enumerate(train_loader):\n",
    "            dcca_opt.zero_grad()\n",
    "\n",
    "            rna_inputs_filtered = Variable(rna_inputs_filtered).to(device)\n",
    "            atac_inputs_filtered = Variable(atac_inputs_filtered).to(device)\n",
    "            rna_inputs_raw = Variable(rna_inputs_raw).to(device)\n",
    "            nn_indices = Variable(nn_indices).to(device)\n",
    "            \n",
    "            embed_rna, embed_atac = dcca_model(rna_inputs_filtered, atac_inputs_filtered)\n",
    "            \n",
    "            #calculate train loss\n",
    "            train_loss = dcca_model.cca_loss(embed_rna, embed_atac)\n",
    "            if hyper[\"add_hinge\"]:\n",
    "                hinge_loss = StructureHingeLoss(\n",
    "                    margin=0.25, \n",
    "                    max_val=1e6, \n",
    "                    lamb_match=hyper[\"lamb_match\"], \n",
    "                    lamb_nn=hyper[\"lamb_nn\"],\n",
    "                    device=device,\n",
    "                )\n",
    "                h_loss = hinge_loss(embed_rna, embed_atac, nn_indices)\n",
    "                #train_loss = train_loss + h_loss\n",
    "                train_loss += hyper['lamb_hinge'] * h_loss\n",
    "                #print(f\"train loss: {train_loss}\")\n",
    "                #print(f\"hinge loss: {h_loss}\")\n",
    "                #print(f\"train loss with hinge: {train_loss}\")\n",
    "            train_loss.backward()\n",
    "            #nn.utils.clip_grad_norm_(toy_model.parameters(), max_norm=hyper[\"clip_grad\"])\n",
    "            dcca_opt.step()\n",
    "            dcca_scheduler.step(train_loss)\n",
    "            train_losses.append(train_loss.item())\n",
    "        avg_train_loss = np.mean(train_losses)\n",
    "        if epoch % 5 == 0:\n",
    "            print(\"Epoch: \" + str(epoch) + \", train loss: \" + str(avg_train_loss))\n",
    "        \n",
    "        #evaluating step\n",
    "        with torch.no_grad():\n",
    "            dcca_model.eval()\n",
    "            knn_acc = []\n",
    "            #mse_acc = []\n",
    "            for idx, samples in enumerate(test_loader):\n",
    "                rna_inputs_filtered = samples[0].float().to(device)\n",
    "                atac_inputs_filtered = samples[1].float().to(device)\n",
    "                rna_inputs_raw = samples[2].float().to(device)\n",
    "\n",
    "                output_rna, output_atac = dcca_model(rna_inputs_filtered, atac_inputs_filtered)\n",
    "                knn_acc.append(knn_criteria(rna_inputs_raw.cpu().detach(), output_rna.cpu().detach(), output_atac.cpu().detach()))\n",
    "            avg_knn_auc = np.mean(knn_acc)\n",
    "            \n",
    "        #checkpointing to save the model with best knn-auc so far\n",
    "        if avg_knn_auc > best_knn_auc:\n",
    "            torch.save({\n",
    "                \"epoch\":epoch,\n",
    "                \"lamb_match\":hyper[\"lamb_match\"],\n",
    "                \"lamb_nn\":hyper[\"lamb_nn\"],\n",
    "                \"lamb_hinge\":hyper[\"lamb_hinge\"],\n",
    "                \"clip_grad\":hyper['clip_grad'],\n",
    "                \"layer_sizes\":hyper['layer_sizes'],\n",
    "                \"model_state_dict\":dcca_model.state_dict(),\n",
    "                \"optimizer_state_dict\":dcca_opt.state_dict(),\n",
    "                \"train_loss\":avg_train_loss,\n",
    "                \"dev_acc\":avg_knn_auc,\n",
    "            }, hyper['checkpoint_path'])\n",
    "        \n",
    "        if epoch % 5 == 0:\n",
    "            print(\"Epoch: \" + str(epoch) + \", acc: \" + str(avg_knn_auc))\n",
    "    test_knn_score, test_mse_score = model_eval(dcca_model, test_data_filtered, test_data_raw, device)\n",
    "    print(\"Final knn_auc: \" + str(test_knn_score))\n",
    "    print(\"Final mse: \" + str(test_mse_score))\n",
    "    return dcca_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(model, test_adata_filtered, test_adata_raw, title):\n",
    "    with torch.no_grad():\n",
    "        model.cpu()\n",
    "        model.eval()\n",
    "        rna_inputs = Variable(torch.from_numpy(test_adata_filtered.X.toarray()).float())\n",
    "        atac_inputs = Variable(torch.from_numpy(test_adata_filtered.obsm[\"mode2\"].toarray()).float())\n",
    "        #rna_inputs = rna_inputs.to(device)\n",
    "        #atac_inputs = atac_inputs.to(device)\n",
    "        z_rna, z_atac = model(rna_inputs, atac_inputs)\n",
    "        \n",
    "    test_adata_raw.obsm[\"aligned\"] = sparse.csr_matrix(z_rna.cpu().detach())\n",
    "    test_adata_raw.obsm[\"mode2_aligned\"] = sparse.csr_matrix(z_atac.cpu().detach())\n",
    "    metrics.plot_multimodal_umap(test_adata_raw, title=title, num_points=100, connect_modalities=True)\n",
    "    knn_score, mse_score = metrics.knn_auc(test_adata_raw), metrics.mse(test_adata_raw)\n",
    "    return knn_score, mse_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the result and give the evalutation matrics score\n",
    "checkpoint = torch.load(hyper[\"checkpoint_path\"], map_location=\"cpu\")\n",
    "dcca_model = DCCA(\n",
    "        n_input1=hyper[\"dim_rna\"], \n",
    "        n_input2=hyper[\"dim_atac\"], \n",
    "        layer_sizes1=hyper[\"layer_sizes\"], \n",
    "        layer_sizes2=hyper[\"layer_sizes\"], \n",
    "        n_out=hyper[\"n_latent\"],\n",
    "        use_all_singvals=False,\n",
    "        device=torch.device(my_device), \n",
    "        use_decode = False,\n",
    "    )\n",
    "dcca_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model_eval(\n",
    "    dcca_model, \n",
    "    test_data_filtered, \n",
    "    test_data_raw, \n",
    "    title = \"DCCA Model with Structure-Preserving Loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similairty(model, test_adata_filtered):\n",
    "    with torch.no_grad():\n",
    "        model.cpu()\n",
    "        model.eval()\n",
    "        rna_inputs = Variable(torch.from_numpy(test_adata_filtered.X.toarray()).float())\n",
    "        atac_inputs = Varialbe(torch.from_numpy(test_adata_filtered.obsm[\"mode2\"].toarray()).float())\n",
    "        z_rna, z_atac = model(rna_inputs, atac_inputs)\n",
    "    cos_score = nn.CosineSimilairty(z_rna, z_atac)\n",
    "    return(cos_score)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mlp_hvg_DCCA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
