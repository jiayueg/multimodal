{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "N7fApNF7xjy3"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install scprep\n",
    "!pip install anndata\n",
    "!pip install scanpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "-L0n8_rB7gPQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata\n",
    "import scprep\n",
    "import scanpy as sc\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tempfile\n",
    "import os\n",
    "import sys\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import load_raw\n",
    "import normalize_tools as nm\n",
    "import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIaWncv9FRlG"
   },
   "source": [
    "# **try out with scicar cell lines dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kdBrFDRFj-x"
   },
   "source": [
    "**1. URLs for raw data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rna_data, atac_data, rna_cells, atac_cells, rna_genes, atac_genes = load_raw.load_raw_cell_lines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcF3DwMRMGPl"
   },
   "source": [
    "**2. select the joint sub-datasets** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "vmgqCzKUTtpo"
   },
   "outputs": [],
   "source": [
    "scicar_data, joint_index, keep_cells_idx = load_raw.merge_data(rna_data, atac_data, rna_cells, atac_cells, rna_genes, atac_genes)\n",
    "#rna_df, atac_df = ann2df(scicar_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHbPxcQb0oBq"
   },
   "source": [
    "# **logcpm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "e62BPkk84kPl"
   },
   "outputs": [],
   "source": [
    "#tryout log cpm scicar_data\n",
    "nm.log_cpm(scicar_data)\n",
    "nm.log_cpm(scicar_data, obsm = \"mode2\", obs = \"mode2_obs\", var = \"mode2_var\")\n",
    "nm.hvg_by_sc(scicar_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uZadFiGYvkkx"
   },
   "outputs": [],
   "source": [
    "nm.hvg_by_sc(scicar_data,  obsm = \"mode2\", obs = \"mode2_obs\", var = \"mode2_var\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zRA9D1KTwKIX",
    "outputId": "7f678584-9235-43fd-ce87-034bd8de8eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14671\n",
      "6057\n"
     ]
    }
   ],
   "source": [
    "print(len(scicar_data.uns[\"mode2_var\"]))\n",
    "print(len(scicar_data.var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hD2gQCx6iIlc"
   },
   "source": [
    "# **define pytorch datasets for RNA and ATAC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "6qQdzukDtFhu"
   },
   "outputs": [],
   "source": [
    "class Merge_Dataset(Dataset):\n",
    "  def __init__(self, adata):\n",
    "    self.rna_data, self.atac_data = self._load_merge_data(adata)\n",
    "\n",
    "  def __len__(self):\n",
    "    #assert(len(self.rna_data) == len(self.atac_data))\n",
    "    return len(self.atac_data)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    rna_sample = self.rna_data.values[idx]\n",
    "    atac_sample = self.atac_data.values[idx]\n",
    "    #return a tensor that for a single observation\n",
    "    return {\"rna_tensor\": torch.from_numpy(rna_sample).float(), \"atac_tensor\": torch.from_numpy(atac_sample).float()}\n",
    "  \n",
    "  def _load_merge_data(self, adata):\n",
    "    rna_df = pd.DataFrame(data = adata.X.toarray(), index = np.array(adata.obs.index), columns = np.array(adata.var.index))\n",
    "    atac_df = pd.DataFrame(data = adata.obsm[\"mode2\"].toarray(), index = np.array(adata.uns[\"mode2_obs\"]), columns = np.array(adata.uns[\"mode2_var\"]))\n",
    "    return rna_df, atac_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4szWON2-cpvS"
   },
   "source": [
    "# **Compute DCCA loss (-corr(H1, H2))**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Q-6pKoruco26"
   },
   "outputs": [],
   "source": [
    "class cca_loss():\n",
    "  def __init__(self, out_dim, device, use_all_singvals=False):\n",
    "    self.out_dim = out_dim #parameter o in original paper\n",
    "    self.use_all_singvals = use_all_singvals\n",
    "    self.device = device\n",
    "  \n",
    "  def loss(self, H1, H2):\n",
    "    r1 = 1e-3\n",
    "    r2 = 1e-3\n",
    "    eps = 1e-9\n",
    "\n",
    "    #transpose H1, H2: m x o -> o x m\n",
    "    H1 = H1.t()\n",
    "    H2 = H2.t()\n",
    "    #assert torch.isnan(H1).sum().item() == 0\n",
    "    #assert torch.isnan(H2).sum().item() == 0\n",
    "\n",
    "    m = H1.size(1)\n",
    "    o1, o2 = H1.size(0), H2.size(0)\n",
    "\n",
    "    #produce the centered data matrices: H1 - 1/m*H1Â·I (same for H2bar)\n",
    "    H1bar = H1 - H1.mean(dim=1).unsqueeze(dim=1)\n",
    "    H2bar = H2 - H2.mean(dim=1).unsqueeze(dim=1)\n",
    "    assert torch.isnan(H1bar).sum().item() == 0\n",
    "    assert torch.isnan(H2bar).sum().item() == 0\n",
    "\n",
    "    SigmaHat12 = (1.0/(m-1))*torch.matmul(H1bar, H2bar.t())\n",
    "    SigmaHat11 = (1.0/(m-1))*torch.matmul(H1bar, H1bar.t()) + r1*torch.eye(o1, device=self.device)\n",
    "    SigmaHat22 = (1.0/(m-1))*torch.matmul(H2bar, H2bar.t()) + r2*torch.eye(o2, device=self.device)\n",
    "    #assert torch.isnan(SigmaHat11).sum().item() == 0\n",
    "    #assert torch.isnan(SigmaHat12).sum().item() == 0\n",
    "    #assert torch.isnan(SigmaHat22).sum().item() == 0\n",
    "\n",
    "    #calculate the root inverse (e.g. SigmaHat11^(-1/2)) using sigular value decomposition\n",
    "    D1, V1 = torch.symeig(SigmaHat11, eigenvectors=True)\n",
    "    D2, V2 = torch.symeig(SigmaHat22, eigenvectors=True)\n",
    "\n",
    "    # ??? probably problemetic in gene count setting\n",
    "    posIdx1 = torch.gt(D1, eps).nonzero()[:, 0]\n",
    "    D1 = D1[posIdx1]\n",
    "    V1 = V1[:, posIdx1]\n",
    "\n",
    "    posIdx2 = torch.gt(D2, eps).nonzero()[:, 0]\n",
    "    D2 = D2[posIdx2]\n",
    "    V2 = V2[:,posIdx2]\n",
    "\n",
    "    #???take care of torch.sqrt\n",
    "    SigmaHatRootInv11 = torch.matmul(torch.matmul(V1, torch.diag((D1)**(-0.5))), V1.t())\n",
    "    SigmaHatRootInv22 = torch.matmul(torch.matmul(V2, torch.diag((D2)**(-0.5))), V2.t())\n",
    "\n",
    "    #calculate T\n",
    "    Tval = torch.matmul(torch.matmul(SigmaHatRootInv11, SigmaHat12), SigmaHatRootInv22)\n",
    "\n",
    "    #calculate corr(H1, H2): matrix trace norm of T or sum of top k singular vals of T\n",
    "    trace_TT = torch.matmul(Tval.t(), Tval)\n",
    "    if self.use_all_singvals:\n",
    "      corr = torch.trace(torch.sqrt(trace_TT))\n",
    "      #assert torch.isnan(corr).item() == 0\n",
    "      \n",
    "    else:\n",
    "      trace_TT = torch.add(trace_TT, (torch.eye(trace_TT.shape[0])*r1).to(self.device))\n",
    "      U, V = torch.symeig(trace_TT, eigenvectors=True)\n",
    "      U = torch.where(U>eps, U, (torch.ones(U.shape).double()*eps).to(self.device))\n",
    "      U = U.topk(self.out_dim)[0]\n",
    "      corr = torch.sum(torch.sqrt(U))\n",
    "    #print(\"loss: \" + str(-corr))\n",
    "    return -corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUl-7w_gcmto"
   },
   "source": [
    "# **define basic models(now just encoder net) for learning latent space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "46TuWH_Rgwnc"
   },
   "outputs": [],
   "source": [
    "class EN_NET(nn.Module):\n",
    "  def __init__(self, n_input, n_out, layer_sizes):\n",
    "    super(EN_NET, self).__init__()\n",
    "    self.n_input = n_input\n",
    "    self.n_out = n_out\n",
    "    self.layers = []\n",
    "    self.layer_sizes = [n_input] + layer_sizes + [n_out]\n",
    "\n",
    "    for layer_idx in range(len(self.layer_sizes)-1):\n",
    "      if layer_idx == len(self.layer_sizes) - 2:\n",
    "        self.layers.append(nn.Linear(self.layer_sizes[layer_idx], self.layer_sizes[layer_idx+1]))\n",
    "      else:\n",
    "        self.layers.append(nn.Linear(self.layer_sizes[layer_idx], self.layer_sizes[layer_idx+1]))\n",
    "        self.layers.append(nn.BatchNorm1d(self.layer_sizes[layer_idx+1]))\n",
    "        self.layers.append(nn.Sigmoid())\n",
    "\n",
    "    self.encoder = nn.Sequential(\n",
    "        *self.layers\n",
    "    )\n",
    "    \n",
    "  def encode(self, x):\n",
    "    return self.encoder(x)\n",
    "\n",
    "  def reparametrize(self, mu, logvar):\n",
    "    #calculate std from log(var)\n",
    "    std = logvar.mul(0.5).exp_()\n",
    "    if torch.cuda.is_available():\n",
    "      eps = torch.cuda.FloatTensor(std.size()).normal_()\n",
    "    else:\n",
    "      eps = torch.FloatTensor(std.size()).normal_()\n",
    "    eps = Variable(eps)\n",
    "    return eps.mul(std).add_(mu)\n",
    "\n",
    "  def forward(self, x):\n",
    "    out = self.encode(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iq4Q758AZn3W"
   },
   "source": [
    "# Assembly Neural Net And Loss Into DCCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "yiiicKn7ZaVo"
   },
   "outputs": [],
   "source": [
    "class DCCA(nn.Module):\n",
    "  def __init__(self, n_input1, n_input2, layer_sizes1, layer_sizes2, n_out, use_all_singvals=False, device=torch.device(\"cpu\")):\n",
    "    super(DCCA, self).__init__()\n",
    "    self.Net1 = EN_NET(n_input1, n_out, layer_sizes1).double()\n",
    "    self.Net2 = EN_NET(n_input2, n_out, layer_sizes2).double()\n",
    "    self.loss = cca_loss(out_dim=n_out, use_all_singvals=use_all_singvals, device=device).loss\n",
    "\n",
    "  def forward(self, x1, x2):\n",
    "    output1 = self.Net1(x1)\n",
    "    output2 = self.Net2(x2)\n",
    "    return output1, output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KsbRfruLdE2j"
   },
   "source": [
    "# **Train Basic Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "0AH8OM02c71Y"
   },
   "outputs": [],
   "source": [
    "#set up all hyper-parameters\n",
    "hyper = {\n",
    "    \"nEpochs\":45,\n",
    "    \"dimRNA\":6057,\n",
    "    \"dimATAC\":14671,\n",
    "    \"n_hidden\":1024,\n",
    "    \"n_out\":64,\n",
    "    \"batchSize\":128,\n",
    "    \"lr\":1e-3,\n",
    "    \"weightDirName\": './checkpoint/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ToOEhyd6m-ZB"
   },
   "outputs": [],
   "source": [
    "#load dataset and split train and test data\n",
    "merge_dataset = Merge_Dataset(scicar_data)\n",
    "train_len = int(len(merge_dataset)*0.8)\n",
    "lengths = [train_len, len(merge_dataset)-train_len]\n",
    "trainset, testset = random_split(merge_dataset, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "_HZZgU6o2Vv5"
   },
   "outputs": [],
   "source": [
    "#use GPU if available\n",
    "my_device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "qcs2gy4KwzCL"
   },
   "outputs": [],
   "source": [
    "#load data loader\n",
    "train_loader = DataLoader(trainset, batch_size=hyper[\"batchSize\"], drop_last=False, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=hyper[\"batchSize\"], drop_last=False, shuffle=False)\n",
    "\n",
    "#load basic models\n",
    "toy_model = DCCA(n_input1=hyper[\"dimRNA\"], \n",
    "                 n_input2=hyper[\"dimATAC\"], \n",
    "                 layer_sizes1=[2048, 1024, 256], \n",
    "                 layer_sizes2=[4096, 2048, 512], \n",
    "                 n_out=hyper[\"n_out\"],\n",
    "                 use_all_singvals=False,\n",
    "                 device=torch.device(my_device))\n",
    "\n",
    "#set up optimizer\n",
    "optimizer = optim.Adam(list(toy_model.parameters()), lr=hyper[\"lr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "q8CX7V2p_tNA"
   },
   "outputs": [],
   "source": [
    "#set up train functions\n",
    "def train(epoch):  \n",
    "  #print(\"Epoch:\"+str(epoch))\n",
    "  train_losses = []\n",
    "  toy_model.train()\n",
    "  for idx, samples in enumerate(train_loader):\n",
    "    rna_inputs = samples[\"rna_tensor\"].double()\n",
    "    atac_inputs = samples[\"atac_tensor\"].double()\n",
    "    rna_inputs, atac_inputs = Variable(rna_inputs), Variable(atac_inputs)\n",
    "    rna_inputs = rna_inputs.to(my_device)\n",
    "    atac_inputs = atac_inputs.to(my_device)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output_rna, output_atac = toy_model(rna_inputs, atac_inputs)\n",
    "    #print(\"before loss calculated\")\n",
    "    loss_epoch = toy_model.loss(output_rna, output_atac)\n",
    "    train_losses.append(loss_epoch.item())\n",
    "    #print(\"after loss calculated\")\n",
    "    loss_epoch.backward()\n",
    "    optimizer.step()\n",
    "      \n",
    "  #loss functions for each modalities\n",
    "  train_loss = np.mean(train_losses)\n",
    "  if epoch % 15 == 0:\n",
    "    print(\"Epoch:\"+str(epoch) + \", loss: \" + str(train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Mc1swrmXm7sZ"
   },
   "outputs": [],
   "source": [
    "def knn_criteria(rna_inputs, atac_inputs, rna_outputs, atac_outputs, proportion_neighbors=0.1, n_svd=100):\n",
    "  n_svd = min([n_svd, min(rna_inputs.shape)-1])\n",
    "  n_neighbors = int(np.ceil(proportion_neighbors*rna_inputs.shape[0]))\n",
    "  X_pca = sklearn.decomposition.TruncatedSVD(n_svd).fit_transform(rna_inputs)\n",
    "  _, indices_true = (\n",
    "      sklearn.neighbors.NearestNeighbors(n_neighbors = n_neighbors).fit(rna_inputs).kneighbors(rna_inputs)\n",
    "  )\n",
    "  _, indices_pred = (\n",
    "      sklearn.neighbors.NearestNeighbors(n_neighbors=n_neighbors).fit(rna_outputs).kneighbors(atac_outputs)\n",
    "  )\n",
    "  neighbors_match = np.zeros(n_neighbors, dtype=int)\n",
    "  for i in range(rna_inputs.shape[0]):\n",
    "    _, pred_matches, true_matches = np.intersect1d(\n",
    "        indices_pred[i], indices_true[i], return_indices=True\n",
    "    )\n",
    "    neighbors_match_idx = np.maximum(pred_matches, true_matches)\n",
    "    neighbors_match += np.sum(np.arange(n_neighbors) >= neighbors_match_idx[:, None], axis = 0,)\n",
    "  neighbors_match_curve = neighbors_match/(np.arange(1, n_neighbors + 1) * rna_inputs.shape[0])\n",
    "  area_under_curve = np.mean(neighbors_match_curve)\n",
    "  return area_under_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Mz5ZLnKCZUEt"
   },
   "outputs": [],
   "source": [
    "def test_model(epoch, test_loader, device):\n",
    "  with torch.no_grad():\n",
    "    toy_model.eval()\n",
    "    knn_acc = []\n",
    "    #mse_acc = []\n",
    "    for idx, samples in enumerate(test_loader):\n",
    "      rna_inputs = samples[\"rna_tensor\"].double()\n",
    "      atac_inputs = samples[\"atac_tensor\"].double()\n",
    "      rna_inputs = rna_inputs.to(device)\n",
    "      atac_inputs = atac_inputs.to(device)\n",
    "\n",
    "      output_rna, output_atac = toy_model(rna_inputs, atac_inputs)\n",
    "      knn_acc.append(knn_criteria(rna_inputs, atac_inputs, output_rna, output_atac))\n",
    "      avg_knn_acc = np.mean(knn_acc)\n",
    "    if epoch % 15 == 0:\n",
    "      print(\"Epoch:\"+str(epoch) + \", average knn_acc: \" + str(avg_knn_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E0nHEL8K7EZ0",
    "outputId": "33037275-08dd-443b-b305-783fcc90998b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-36b177968e57>:35: UserWarning: torch.symeig is deprecated in favor of torch.linalg.eigh and will be removed in a future PyTorch release.\n",
      "The default behavior has changed from using the upper triangular portion of the matrix by default to using the lower triangular portion.\n",
      "L, _ = torch.symeig(A, upper=upper)\n",
      "should be replaced with\n",
      "L = torch.linalg.eigvalsh(A, UPLO='U' if upper else 'L')\n",
      "and\n",
      "L, V = torch.symeig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L, V = torch.linalg.eigh(A, UPLO='U' if upper else 'L') (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448234945/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:2500.)\n",
      "  D1, V1 = torch.symeig(SigmaHat11, eigenvectors=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, loss: -39.87804021644458\n",
      "Epoch:0, average knn_acc: 0.0947296360156937\n",
      "Epoch:15, loss: -45.429816941867486\n",
      "Epoch:15, average knn_acc: 0.08020917925890883\n",
      "Epoch:30, loss: -47.998591428690375\n",
      "Epoch:30, average knn_acc: 0.03587534406532303\n"
     ]
    }
   ],
   "source": [
    "max_iter = hyper[\"nEpochs\"]\n",
    "for epoch in range(max_iter):\n",
    "  train(epoch)\n",
    "  test_model(epoch, test_loader, my_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0LFEBScjW5Bu",
    "outputId": "ca4244af-30e6-4468-c50e-b578a43c4685"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03049226498042545\n",
      "1.0063349708800973\n"
     ]
    }
   ],
   "source": [
    "atac_inputs = Variable(torch.from_numpy(merge_dataset.atac_data.values).double())\n",
    "rna_inputs = Variable(torch.from_numpy(merge_dataset.rna_data.values).double())\n",
    "toy_model.eval()\n",
    "out_rna, out_atac = toy_model(rna_inputs, atac_inputs)\n",
    "scicar_data.obsm[\"aligned\"] = sparse.csr_matrix(out_rna.cpu().detach())\n",
    "scicar_data.obsm[\"mode2_aligned\"] = sparse.csr_matrix(out_atac.cpu().detach())\n",
    "print(metrics.knn_auc(scicar_data))\n",
    "print(metrics.mse(scicar_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "-mZFHO0j5vwe",
    "outputId": "af4818e5-4905-4f38-ff28-98646d8a7b73",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-12a5d4ce04f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                  \u001b[0muse_all_singvals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                  device=torch.device(my_device))\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcheckpoint_out64\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_out64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel_out64\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_out64\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_state_dict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'path_out64' is not defined"
     ]
    }
   ],
   "source": [
    "model_out = DCCA(n_input1=hyper[\"dimRNA\"], \n",
    "                 n_input2=hyper[\"dimATAC\"], \n",
    "                 layer_sizes1=[2048, 1024, 256], \n",
    "                 layer_sizes2=[4096, 2048, 512], \n",
    "                 n_out=hyper[\"n_out\"],\n",
    "                 use_all_singvals=False,\n",
    "                 device=torch.device(my_device))\n",
    "checkpoint_out64 = torch.load(path_out64)\n",
    "model_out64.load_state_dict(checkpoint_out64[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97PHeKh1TUL9"
   },
   "outputs": [],
   "source": [
    "path_out100 = \"\"\n",
    "torch.save({\n",
    "    \"num_iter\": hyper[\"nEpochs\"],\n",
    "    \"n_out\": hyper[\"n_out\"],\n",
    "    \"model_state_dict\": toy_model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    \"knn_auc\": 9.643159972821067e-06,\n",
    "    \"mse\": 0.985969183721269\n",
    "}, path_out100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mlp_hvg_DCCA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
